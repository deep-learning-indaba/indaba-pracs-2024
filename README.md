# Deep Learning Indaba Practicals 2024

This year we offer all of our practicals in both English and French! Scroll down to find the French versions of the practicals, under the English versions for each day.

*Cette ann√©e, nous proposons tous nos travaux pratiques en anglais et en fran√ßais ! Faites d√©filer la page vers le bas pour trouver les versions fran√ßaises des travaux pratiques, sous les versions anglaises de chaque jour.*

## Day 1 (foundations 1) ‚Äì English

| Topic üí• | Description üìò |
|:----|----|
| [Introduction to ML [using JAX]](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Intro_to_ML_using_JAX/Introduction_to_ML_using_JAX.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Intro_to_ML_using_JAX/Introduction_to_ML_using_JAX.ipynb) <br /> <br />                                                           | In this tutorial, we will learn about some of the high-level concepts behind machine learning (ML) and the basics of JAX, a numerical computing library that we will use for our practicals. Finally, we will learn about the fundamentals of supervised learning, from linear regression, all the way to neural networks, learning the fundamentals of optimisation along the way.  |
| Introduction to Probabilistic Thinking and Programming <br /> <br />[Part 1](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Probabilistic_Thinking_and_Programming/Probabilistic_Thinking_and_Programming_Part1.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Probabilistic_Thinking_and_Programming/Probabilistic_Thinking_and_Programming_Part1.ipynb)<br /> <br />[Part 2](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Probabilistic_Thinking_and_Programming/Probabilistic_Thinking_and_Programming_Part2.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Probabilistic_Thinking_and_Programming/Probabilistic_Thinking_and_Programming_Part2.ipynb)<br /> <br />                                                           | Probabilistic thinking and working with probability distributions are very powerful tools for any machine learning practitioner. This practical introduces a powerful approach to solving real-world problems called **probabilistic programming**, and builds a helpful foundation for reasoning about probabilistic models and events. |
| [Graph Neural Networks](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Graph_Neural_Networks/Graph_Neural_Networks.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Graph_Neural_Networks/Graph_Neural_Networks.ipynb)<br /> <br />[Extended Version](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Graph_Neural_Networks/Graph_Neural_Networks_Extended.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Graph_Neural_Networks/Graph_Neural_Networks_Extended.ipynb)<br /> <br />                                                           | In this tutorial, we will be learning about Graph Neural Networks (GNNs), a topic which has exploded in popularity in both research and industry. We will start with a refresher on graph theory, then dive into how GNNs work from a high level. Next we will cover some popular GNN implementations and see how they work in practice. |


## Jour 1 (connaissances 1) ‚Äì Fran√ßais

| Sujet üí• | Description üìò |
|:----|----|
| [Introduction au Machine Learning [en utilisant JAX]](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Intro_to_ML_using_JAX/Introduction_to_ML_using_JAX_French.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Intro_to_ML_using_JAX/Introduction_to_ML_using_JAX_French.ipynb) <br /> <br />                                                           | Dans ce tutoriel, nous allons d√©couvrir certains des concepts de haut niveau derri√®re l'apprentissage automatique (ANGLAIS machine learning, ML) et les bases de JAX, une biblioth√®que de calcul num√©rique que nous utiliserons pour nos travaux pratiques. Enfin, nous aborderons les fondamentaux de l'apprentissage supervis√© (ANGLAIS supervised learning), de la r√©gression lin√©aire (linear regression) jusqu'aux r√©seaux de neurones (ANGLAIS neural networks), en apprenant les principes de l'optimisation en cours de route. |
| Introduction √† la pens√©e et √† la programmation probabilistes <br /> <br />[Part 1](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Probabilistic_Thinking_and_Programming/Probabilistic_Thinking_and_Programming_Part1_French.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Probabilistic_Thinking_and_Programming/Probabilistic_Thinking_and_Programming_Part1_French.ipynb)<br /> <br />[Part 2](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Probabilistic_Thinking_and_Programming/Probabilistic_Thinking_and_Programming_Part2_French.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Probabilistic_Thinking_and_Programming/Probabilistic_Thinking_and_Programming_Part2_French.ipynb)<br /> <br />                                                           | La pens√©e probabiliste et l'utilisation de distributions de probabilit√© sont des outils tr√®s puissants pour tout praticien du machine learning.Ce guide pratique introduit une approche puissante pour r√©soudre des probl√®mes du monde r√©el appel√©e **programmation probabiliste**, et construit une base solide pour raisonner sur les mod√®les et les √©v√©nements probabilistes. |
| [R√©seaux de neurones en graphes](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Graph_Neural_Networks/Graph_Neural_Networks_French.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Graph_Neural_Networks/Graph_Neural_Networks_French.ipynb)<br /> <br />[Version √©tendue](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Graph_Neural_Networks/Graph_Neural_Networks_Extended_French.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Graph_Neural_Networks/Graph_Neural_Networks_Extended_French.ipynb)<br /> <br />                                                           | Ce tutoriel porte sur les r√©seaux de neurones en graphes (Graph Neural Networks en anglais, ou tout simplement GNNs), un sujet qui a explos√© en popularit√© tant dans la recherche que dans l'industrie. Nous commencerons par une r√©vision de la th√©orie des graphes, puis nous plongerons dans le fonctionnement des GNNs √† un niveau g√©n√©ral. Ensuite, nous couvrirons quelques impl√©mentations populaires de GNNs et verrons comment elles fonctionnent en pratique. |


## Day 2 (foundations 2) ‚Äì English

| Topic üí• | Description üìò |
|:----|----|
| [Responsible AI](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Responsible_AI/Responsible_AI.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Responsible_AI/Responsible_AI.ipynb) <br /> <br />                                                           | This notebook provides a hands-on exploration of responsible AI through two parts: analyzing ProPublica's analysis of the COMPAS risk assessment tool and examining biases using the Fairlearn toolkit. The first part focuses on ProPublica's investigation of COMPAS, and specifically on how its recidivism scores vary by race and sex. This involves data import, preprocessing, exploratory analysis, and logistic regression modeling to reproduce and interpret ProPublica's findings. The second part transitions to detecting and mitigating biases using Fairlearn, a library designed to assess and improve fairness in machine learning models. By engaging with both theoretical and practical aspects of responsible AI, this notebook aims to enhance understanding of bias in AI systems and the tools available to address it.  |
| LLM Foundations  | Coming soon! |
| [Diffusion Models: Building your own Stable Diffusion](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Diffusion_Models/Diffusion_Models.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Diffusion_Models/Diffusion_Models.ipynb) <br /> <br />                                                           | Denoising Diffusion Models are a variant of generative modelling that serve as the backbone in recent advances in image synthesis - including Dall-E, Stable Diffusion, and Midjourney. These models utilise an iterative denoising process during generation to produce high-quality samples. In this practical, we will explore the fundamentals of diffusion models, the intuition behind them, and how they work in practice. By the end of the practical, we will have covered all the steps required to train one of these models from scratch!  |
| From Zero to 2048: Building RL environment with JAX <br /> <br />[Beginner Level](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/RL_2048/From_Zero_to_2048_Building_RL_environment_with_JAX_(Beginner_Level).ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/RL_2048/From_Zero_to_2048_Building_RL_environment_with_JAX_(Beginner_Level).ipynb)<br /> <br />[Intermediate Level](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/RL_2048/From_Zero_to_2048_Building_RL_environment_with_JAX_(Intermediate_Level).ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/RL_2048/From_Zero_to_2048_Building_RL_environment_with_JAX_(Intermediate_Level).ipynb) <br /> <br />                                                           | In this practical, we will explore building a JAX environment for the game "2048". In Reinforcement Learning (RL), the roles of an Agent and an Environment are crucial, as the environment is essential for testing and training RL algorithms. On the other side, JAX has become a key tool for advancing RL algorithm implementation, enabling more efficient architectures and the creation of distributed systems that can be trained in minutes on local GPU machines. However, to achieve this efficiency, the environment needs to be "jaxified". The importance of adapting environments for JAX is highlighted by the growing focus on jax-environments repositories like Jumanji, Gymnax, and JaxMARL.  |


## Jour 2 (connaissances 2) ‚Äì Fran√ßais

| Sujet üí• | Description üìò |
|:----|----|
| [IA Responsable](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Responsible_AI/Responsible_AI_French.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Responsible_AI/Responsible_AI_French.ipynb) <br /> <br />                                                           | Ce bloc-notes propose une exploration pratique de l'IA responsable en deux parties : analyser l'analyse de ProPublica de l'outil d'√©valuation des risques COMPAS et examiner les biais √† l'aide de la bo√Æte √† outils Fairlearn. La premi√®re partie se concentre sur l'enqu√™te de ProPublica sur COMPAS, en particulier sur la mani√®re dont ses scores de r√©cidive varient selon la race et le sexe. Cela implique l'importation de donn√©es, le pr√©traitement, l'analyse exploratoire et la mod√©lisation par r√©gression logistique pour reproduire et interpr√©ter les r√©sultats de ProPublica. La deuxi√®me partie passe √† la d√©tection et √† l'att√©nuation des biais √† l'aide de Fairlearn, une biblioth√®que con√ßue pour √©valuer et am√©liorer l'√©quit√© des mod√®les de Machine Learning. En abordant les aspects √† la fois th√©oriques et pratiques de l'IA responsable, ce bloc-notes vise √† am√©liorer la compr√©hension des biais dans les syst√®mes d'IA et des outils disponibles pour y rem√©dier.  |
| Introduction aux LLMs  | Bient√¥t disponible ! |
| [Diffusion Models : Construire votre propre Stable Diffusion](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Diffusion_Models/Diffusion_Models_French.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Diffusion_Models/Diffusion_Models_French.ipynb) <br /> <br />                                                           | Les mod√®les de diffusion √† d√©bruitage (Denoising Diffusion Models) sont une variante de la mod√©lisation g√©n√©rative qui constitue l'√©pine dorsale des progr√®s r√©cents en mati√®re de synth√®se d'images - notamment Dall-E, Stable Diffusion et Midjourney. Ces mod√®les utilisent un processus de d√©bruitage it√©ratif pendant la g√©n√©ration afin de produire des √©chantillons de haute qualit√©. Dans ce TP, nous explorerons les principes fondamentaux des mod√®les de diffusion, l'intuition qui les sous-tend et leur fonctionnement en pratique. √Ä la fin du TP, nous aurons couvert toutes les √©tapes n√©cessaires √† l'apprentissage d'un de ces mod√®les √† partir de z√©ro ! |
| De z√©ro √† 2048 : Construire un environnement RL avec JAX <br /> <br />[Begginer Level](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/RL_2048/From_Zero_to_2048_Building_RL_environment_with_JAX_(Beginner_Level)_French.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/RL_2048/From_Zero_to_2048_Building_RL_environment_with_JAX_(Beginner_Level)_French.ipynb)<br /> <br />[Intermediate Level](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/RL_2048/From_Zero_to_2048_Building_RL_environment_with_JAX_(Intermediate_Level)_French.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/RL_2048/From_Zero_to_2048_Building_RL_environment_with_JAX_(Intermediate_Level)_French.ipynb) <br /> <br />                                                           | Dans cette pratique, nous allons explorer la construction d'un environnement JAX pour le jeu ¬´ 2048 ¬ª. Dans l'apprentissage par renforcement (RL), les r√¥les d'un agent et d'un environnement sont cruciaux, car l'environnement est essentiel pour tester et entra√Æner les algorithmes RL. D'autre part, JAX est devenu un outil cl√© pour faire progresser la mise en ≈ìuvre des algorithmes d'apprentissage par renforcement, permettant des architectures plus efficaces et la cr√©ation de syst√®mes distribu√©s qui peuvent √™tre entra√Æn√©s en quelques minutes sur des machines GPU locales. Cependant, pour atteindre cette efficacit√©, l'environnement doit √™tre ¬´ jaxifi√© ¬ª. L'importance de l'adaptation des environnements pour JAX est soulign√©e par l'int√©r√™t croissant pour les d√©p√¥ts (repositories) d'environnements jax tels que Jumanji, Gymnax, et JaxMARL.  |


## Day 3 (applications) ‚Äì English

| Topic üí• | Description üìò |
|:----|----|
| [AI for Biology](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/AI_for_Biology/AI_for_Biology.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/AI_for_Biology/AI_for_Biology.ipynb) <br /> <br />                                                         |In this practical, we will learn about some of the major application areas of AI in the biosciences, go over the role of DNA and how DNA language models are trained, extract and explore DNA embeddings using a pre-trained state-of-the-art DNA language model, and dive into a hands-on problem on modelling DNA sequences and their properties.  |
| [Fine-tuning and resource-efficient LLMs for NLP](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Low_Resource_LLMs/Indaba_2024_Low_Resource_LLM.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Low_Resource_LLMs/Indaba_2024_Low_Resource_LLM.ipynb) <br /> <br />   | Low-resource NLP (Natural Language Processing) refers to the study and development of NLP models and systems for languages, tasks, or domains that have limited data and resources available. These can include languages with fewer digital text corpora, limited computational tools, or less-developed linguistic research. In this practical, we will explore data scarcity and compute resource limitations in low-resource NLP, and introduce some ways to address these challenges with parameter-efficient finetuning of LLMs. |
| [From Centralised to Decentralised Training: An Intro to Federated Learning](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Federated_Learning/Federated_Learning.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Federated_Learning/Federated_Learning.ipynb) <br /> <br />                                                         |Federated Learning (FL) is a growing research area with a number of existing applications and numerous reseach papers presented at conferences, journals and workshops each year. While this is great for research and industry experts who have a thriving FL community, the rapid innovations in FL implicitly create a barrier of entry for those wanting to understand FL from a first principles perspective. Despite FL being a relatively simple concept at its core, it can be implemented in numerous ways and includes a great deal of domain-specific jargon that can leave newcomers feeling overwhelmed or alientated initially. Our practical is aimed at bridging this gap. We want to provide a beginner-focused introduction to FL, stripping away any fancy bells and whistles such that focus is placed on the foundational concepts. We want you to leave the practical with a good enough understanding such that you can explain Federated Learning to someone else, and such that you can intuit when Federated Learning could be useful in future scenarios you might encounter.  |
| [Recommender Systems](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Recommender_Systems/Recommender_Systems.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Recommender_Systems/Recommender_Systems.ipynb)<br /> <br />[Building Recommender Systems using GNNs (Part 2)](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Recommender_Systems/GNNs_for_Recommendations.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Recommender_Systems/GNNs_for_Recommendations.ipynb) <br /> <br />                                                           | Recommender Systems are probably one of the most ubiquitous types of machine learning models that we encounter in our online life. They influence what we see in our social media feeds, the products we buy, the music we listen to, the food we eat, and the movies we watch. In this practical, we take you through some of the techniques popularly used in industry to recommend the content you see online by building our very own movie-recommender system.  |


## Jour 3 (applications) ‚Äì Fran√ßais

| Sujet üí• | Description üìò |
|:----|----|
| [IA pour la Biologie](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/AI_for_Biology/AI_for_Biology_French.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/AI_for_Biology/AI_for_Biology_French.ipynb) <br /> <br />                                                         |Dans cette pratique, nous allons : apprendre √† conna√Ætre certains des principaux domaines d'application de l'IA dans les biosciences, passer en revue le r√¥le de l'ADN et la mani√®re dont les mod√®les de langage ADN sont entra√Æn√©s, extraire et explorer les plongements ADN √† l'aide d'un mod√®le de langage ADN pr√©-entra√Æn√© √† la pointe de la technologie, et nous plonger dans un probl√®me pratique de mod√©lisation des s√©quences d'ADN et de leurs propri√©t√©s.  |
| [Finetuning et LLM √©conome en ressources pour le NLP](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Low_Resource_LLMs/Indaba_2024_Low_Resource_LLM_FR.ipynb)) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Low_Resource_LLMs/Indaba_2024_Low_Resource_LLM_FR.ipynb) <br /> <br />  | Le traitement du langage naturel (NLP) √† faibles ressources fait r√©f√©rence √† l'√©tude et au d√©veloppement de mod√®les et de syst√®mes de traitement du langage naturel (NLP) pour les langues, les t√¢ches ou les domaines pour lesquels les donn√©es et les ressources disponibles sont limit√©es. Il peut s'agir de langues avec moins de corpus de textes num√©riques, d'outils informatiques limit√©s ou de recherches linguistiques moins d√©velopp√©es. Dans cette √©tude pratique, nous explorerons la raret√© des donn√©es et les limitations des ressources informatiques dans le traitement du langage naturel √† faibles ressources, et nous pr√©senterons quelques moyens de relever ces d√©fis gr√¢ce √† un r√©glage fin des LLM efficace en termes de param√®tres. |
| [De l'entra√Ænement centralis√© √† l'entra√Ænement d√©centralis√© : une introduction au Federated Learning](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Federated_Learning/Federated_Learning_French.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Federated_Learning/Federated_Learning_French.ipynb) <br /> <br />                                                         |Le Federated Learning (FL) est un domaine de recherche en pleine croissance avec un certain nombre d'applications existantes et de nombreux articles de recherche pr√©sent√©s chaque ann√©e lors de conf√©rences, dans des revues et des ateliers. Bien que cela soit b√©n√©fique pour les experts de la recherche et de l'industrie qui disposent d'une communaut√© FL florissante, les innovations rapides dans le domaine du FL cr√©ent implicitement une barri√®re √† l'entr√©e pour ceux qui souhaitent entrer dans cet espace et comprendre le FL √† partir des premiers principes. Bien que le FL soit un concept relativement simple √† la base, il peut √™tre mis en ≈ìuvre de nombreuses fa√ßons et comprend un grand nombre de jargons sp√©cifiques au domaine qui peuvent laisser les nouveaux arrivants se sentir d√©pass√©s ou ali√©n√©s au d√©part. Notre approche pratique vise √† combler cette lacune. Nous voulons fournir une introduction au FL ax√©e sur les d√©butants, en supprimant toutes les fioritures afin que l'accent soit mis sur les concepts fondamentaux. Nous voulons que vous quittiez cette formation pratique avec une compr√©hension suffisante pour pouvoir expliquer le Federated Learning √† quelqu'un d'autre et pour pouvoir deviner quand le Federated Learning pourrait √™tre utile dans les futurs sc√©narios que vous pourriez rencontrer.  |
| [Syst√®mes de recommandation](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Recommender_Systems/Recommender_Systems_French.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Recommender_Systems/Recommender_Systems_French.ipynb)<br /> <br />[Construire des syst√®mes de recommandation √† l'aide de GNN (Partie 2)](https://github.com/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Recommender_Systems/GNNs_for_Recommendations_French.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/Recommender_Systems/GNNs_for_Recommendations_French.ipynb) <br /> <br />                                                           | Les syst√®mes de recommandation sont probablement l'un des types de mod√®les de ML les plus omnipr√©sents que nous rencontrons dans notre vie en ligne. Ils influencent ce que nous voyons dans nos flux de m√©dias sociaux, les produits que nous achetons, la musique que nous √©coutons, la nourriture que nous mangeons et les films que nous regardons. Dans ce TP, nous vous pr√©sentons quelques-unes des techniques couramment utilis√©es dans l'industrie qui recommandent le contenu que vous voyez en ligne en construisant notre propre syst√®me de recommandation de films. |
