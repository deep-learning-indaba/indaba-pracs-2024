{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2s4kN_QPQVe"
      },
      "source": [
        "# üß¨ **AI for Biology** üß¨\n",
        "\n",
        "<a href=\"https://ibb.co/Cs0GsQD\"><img src=\"https://i.ibb.co/mFzWF4g/d3ccc3f8-69e2-428f-8ec4-896221936735.webp\" alt=\"Scifi collage of AI in biology\" border=\"0\"></a>\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2024/blob/main/practicals/AI_for_Biology/AI_for_Biology_French.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "¬© Deep Learning Indaba 2024. Apache License 2.0.\n",
        "\n",
        "**Auteurs :** Natasha Latysheva\n",
        "\n",
        "**Sujets :** Biologie, ADN, mod√®les de langage de grande taille, plongements (embeddings) , apprentissage supervis√© et auto-supervis√©.\n",
        "\n",
        "**Niveau :** D√©butant\n",
        "\n",
        "**Objectifs :** Comprendre les plongements d'ADN et entra√Æner un mod√®le en les utilisant pour r√©soudre un probl√®me biologique pratique\n",
        "\n",
        "# AI for Biology\n",
        "Bienvenue dans le tutoriel pratique **AI for Biology** ! Dans cette session, nous allons :\n",
        "- D√©couvrir certains des principaux domaines d'application de l'IA dans les biosciences\n",
        "- Examiner le r√¥le de l'ADN et la mani√®re dont les mod√®les de langage d'ADN sont entra√Æn√©s\n",
        "- Extraire et explorer les plongements (embeddings) de l'ADN en utilisant un mod√®le de langage d'ADN pr√©-entra√Æn√© √† la pointe de la technologie\n",
        "- Se plonger dans un probl√®me pratique de mod√©lisation des s√©quences d'ADN et de leurs propri√©t√©s\n",
        "\n",
        "**Pr√©requis :**\n",
        "\n",
        "1. Connaissances de base en Python\n",
        "2. Aucune connaissance en biologie requise\n",
        "\n",
        "**Plan du tutoriel pratique :**\n",
        "\n",
        "<div align=\"left\">\n",
        "<a href=\"https://ibb.co/jryGWdL\"><img src=\"https://i.ibb.co/kS409ph/Screenshot-2024-07-23-at-21-48-22.png\" alt=\"Screenshot-2024-07-23-at-21-48-22\" width=\"400\" border=\"0\"></a>\n",
        "</div>\n",
        "\n",
        "\n",
        "\n",
        "**Avant de commencer :**\n",
        "\n",
        "Pour ce tutoriel pratique, vous devrez utiliser un GPU pour acc√©l√©rer l'entra√Ænement. Pour ce faire, allez dans le menu \"Ex√©cution\" de Colab, s√©lectionnez \"Changer le type d'ex√©cution\", puis dans le menu contextuel, choisissez \"GPU\" dans la zone \"Acc√©l√©rateur mat√©riel\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaYkP5A7bGqF"
      },
      "source": [
        "Nous pouvons √©galement d√©j√† installer et importer tous les packages requis :\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4boGA9rYdt9l"
      },
      "outputs": [],
      "source": [
        "## Installer et importer tout ce qui est requis, t√©l√©charger les mod√®les, t√©l√©charger les donn√©es.\n",
        "# @title Installer et importer les packages n√©cessaires. (Ex√©cuter la cellule)\n",
        "%%capture\n",
        "\n",
        "# Installations.\n",
        "!pip install transformers datasets\n",
        "!pip install biopython requests h5py\n",
        "!pip install jax\n",
        "!pip install flax\n",
        "\n",
        "# Importations.\n",
        "import os\n",
        "import random\n",
        "import tqdm\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import grad, jit, vmap\n",
        "import flax.linen as nn\n",
        "import optax\n",
        "import torch\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import h5py\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from Bio import Entrez, SeqIO\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "\n",
        "# T√©l√©charger le mod√®le de langage d'ADN et le tokenizer.\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"InstaDeepAI/nucleotide-transformer-v2-50m-multi-species\",\n",
        "    trust_remote_code=True)\n",
        "\n",
        "language_model = AutoModelForMaskedLM.from_pretrained(\n",
        "    \"InstaDeepAI/nucleotide-transformer-v2-50m-multi-species\",\n",
        "    trust_remote_code=True)\n",
        "\n",
        "# T√©l√©charger les plongements pr√©-extraits pour des cha√Ænes d'ADN al√©atoires.\n",
        "ROOT_DIR = \"https://raw.githubusercontent.com/deep-learning-indaba/indaba-pracs-2024/main/practicals/AI_for_Biology/data/\"\n",
        "\n",
        "import pandas as pd\n",
        "dna_sequences = pd.read_csv(os.path.join(ROOT_DIR, \"dna_sequences.csv\"))\n",
        "# (train_df) Donn√©es d'entra√Ænement\n",
        "train_df = pd.read_feather(os.path.join(ROOT_DIR, \"train_embeddings.feather\"))\n",
        "# (valid_df) Donn√©es de validation\n",
        "valid_df = pd.read_feather(os.path.join(ROOT_DIR, \"valid_embeddings.feather\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Jh4BKgUcNHw"
      },
      "outputs": [],
      "source": [
        "# @title V√©rifier TPU/GPU. (Ex√©cuter la cellule)\n",
        "import jax\n",
        "num_devices = jax.device_count()\n",
        "device_type = jax.devices()[0].device_kind\n",
        "print(f\"Trouv√© {num_devices} dispositif(s) JAX de type {device_type}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYna9Z1iZwuH"
      },
      "source": [
        "## 1. Applications de l'IA en Biologie\n",
        "\n",
        "L'IA devient de plus en plus courante dans le domaine biologique et a connu des avanc√©es r√©centes vraiment passionnantes. Cependant, le domaine en est encore √† ses d√©buts - cela signifie qu'il reste beaucoup de travail int√©ressant √† faire et que c'est un excellent moment pour s'y impliquer !\n",
        "\n",
        "Voici un rapide aper√ßu de quelques travaux r√©cents int√©ressants en IA appliqu√©e √† la biologie dans diff√©rents domaines.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6EQ9z2D81Gi"
      },
      "source": [
        "### Diagnostics m√©dicaux\n",
        "\n",
        "Les mod√®les de classification du cancer de la peau tels que [celui du MIT](https://www.science.org/doi/10.1126/scitranslmed.abb3652) atteignent des performances comparables √† celles de dermatologues certifi√©s¬†:\n",
        "<div align=\"center\">\n",
        "    <img src=\"https://wp.technologyreview.com/wp-content/uploads/2021/06/automated-melanoma-detection-small2.gif?w=400\" alt=\"GIF de d√©tection automatis√©e du m√©lanome\">\n",
        "</div>\n",
        "\n",
        "\n",
        "Un [mod√®le de DeepMind](https://www.nature.com/articles/s41591-018-0107-6) de segmentation et de classification des maladies de la r√©tine est capable de diagnostiquer de nombreuses affections ophtalmiques √† partir de scans r√©tiniens 3D. Ses performances sont similaires √† celles des meilleurs sp√©cialistes de la r√©tine et surpassent celles de certains experts humains¬†:\n",
        "\n",
        "\n",
        "\n",
        "<div align=\"center\">\n",
        "    <img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cnyoA2T8BFZRBYWnUlYEtQ.gif\" alt=\"GIF de segmentation du scan r√©tinien\">\n",
        "</div>\n",
        "\n",
        "[Le mod√®le SynthSR de Harvard et de l'UCL](https://www.science.org/doi/10.1126/sciadv.add3607) peut prendre des IRM c√©r√©brales cliniques avec n'importe quel contraste, orientation et r√©solution et les transformer en images 3D haute r√©solution¬†:\n",
        "\n",
        "<div align=\"center\">\n",
        "    <img src=\"https://www.science.org/cms/10.1126/sciadv.add3607/asset/7a6c5ed9-af95-41d2-b888-2b5a653ea55b/assets/images/large/sciadv.add3607-f1.jpg\" alt=\"Mod√®le de scan IRM SynthSR\" width=\"400\">\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVYcazlUZ-vP"
      },
      "source": [
        "### Pharmacie et d√©veloppement de m√©dicaments\n",
        "\n",
        "[Exscientia](https://www.exscientia.com/) a d√©velopp√© le premier m√©dicament con√ßu par l'IA √† entrer dans des essais cliniques (DSP-1181, destin√© au traitement du trouble obsessionnel-compulsif).\n",
        "\n",
        "De nombreux efforts de d√©couverte de m√©dicaments assist√©s par l'IA utilisent des mod√®les pour pr√©dire la force avec laquelle les petites mol√©cules se lieront √† diff√©rentes r√©gions d'une prot√©ine cible impliqu√©e dans une maladie donn√©e :\n",
        "\n",
        "<div align=\"center\">\n",
        "    <img src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/03/bionemo_featured.jpeg\" alt=\"representation d'une poche g√©n√©rale\" width=\"400\">\n",
        "</div>\n",
        "\n",
        "\n",
        "[BenevolentAI](https://www.benevolent.com/about-us/sustainability/covid-19/) a utilis√© l'IA pour identifier le Baricitinib, √† l'origine un m√©dicament contre l'arthrite, comme traitement potentiel contre la COVID-19 en 48¬†heures en utilisant son graphique de connaissances.\n",
        "\n",
        "\n",
        "<div align=\"center\">\n",
        "    <img src=\"https://www.benevolent.com/application/files/6616/7458/5885/Corona_Baricitinib.png\" alt=\"BenevolentAI Baricitinib\" width=\"400\">\n",
        "</div>\n",
        "\n",
        "[Lien vers une vid√©o YouTube intitul√©e ¬´¬†BenevolentAI ¬∑ AI-Enabled Drug Discovery¬†¬ª](https://www.youtube.com/watch?v=RPBDhogTIT0)\n",
        "\n",
        "[Recursion Pharmaceuticals](https://www.recursion.com/) est r√©put√©e pour son criblage et son optimisation √† haut d√©bit, et a d√©velopp√© des mod√®les avanc√©s d'imagerie cellulaire :\n",
        "\n",
        "<div align=\"center\">\n",
        "    <img src=\"https://miro.medium.com/v2/resize:fit:1400/0*yVLwEtfojWdnMZfA\" alt=\"Recursion\" width=\"800\">\n",
        "</div>\n",
        "\n",
        "\n",
        "Ils entra√Ænent des mod√®les pour pr√©dire les pixels manquants dans les images de cellules de la m√™me mani√®re que les grands mod√®les de langage pr√©disent les mots manquants ou masqu√©s dans les phrases :\n",
        "\n",
        "<div align=\"center\">\n",
        "    <img src=\"https://blogs.nvidia.com/wp-content/uploads/2024/05/Recursion-Phenom-AI-model-animation.gif\" alt=\"Recursion\" width=\"800\">\n",
        "</div>\n",
        "\n",
        "Parmi les autres startups qui font de l'apprentissage profond pour la d√©couverte de m√©dicaments, citons Atomwise, insitro, Insilico Medicine, Deep Genomics et Deepcell.\n",
        "\n",
        "En outre, de grandes soci√©t√©s pharmaceutiques comme Illumina, GSK et Genentech ont mis en place des √©quipes internes d'apprentissage profond et ont d√©velopp√© des mod√®les influents tels que [SpliceAI](https://www.cell.com/cell/pdf/S0092-8674(18)31629-5.pdf) (un mod√®le qui comprend l'√©pissage) et [PrimateAI](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6237276/) (un mod√®le qui pr√©dit l'effet clinique des mutations dans les prot√©ines), ce qui t√©moigne de l'int√©gration croissante de l'apprentissage profond dans les flux de travail en biologie.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjN3f4S4aIPg"
      },
      "source": [
        "### Biologie mol√©culaire\n",
        "\n",
        "Le [mod√®le AlphaFold de DeepMind](https://www.nature.com/articles/s41586-021-03819-2) a r√©volutionn√© le domaine de la pr√©diction de la structure des prot√©ines, gagnant une adoption et une reconnaissance g√©n√©ralis√©es dans les milieux universitaires, biotechnologiques et pharmaceutiques :\n",
        "\n",
        "<div align=\"center\">\n",
        "    <img src=\"https://spectrum.ieee.org/media-library/two-examples-of-protein-targets-in-the-free-modelling-category-in-green-is-the-experimental-result-in-blue-is-the-computationa.gif?id=25559695&width=2400&height=1358\" alt=\"Pr√©dictions d'AlphaFold\" width=\"800\">\n",
        "</div>\n",
        "\n",
        "\n",
        "Des chercheurs d'[EvolutionaryScale](https://www.evolutionaryscale.ai/blog/esm3-release) ont utilis√© leur mod√®le de langage prot√©ique ESM3 pour concevoir une nouvelle prot√©ine fluorescente assez distincte des prot√©ines fluorescentes pr√©sentes dans la nature :\n",
        "\n",
        "<div align=\"center\">\n",
        "    <img src=\"https://cdn.prod.website-files.com/6606dc3fd5f6645318003e20/667a5bb780d0ada7dc37d1c0_image%20(1).png\" alt=\"ESM3\" width=\"400\">\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "balHN65uaPS-"
      },
      "source": [
        "### √âcologie et conservation\n",
        "\n",
        "[Rainforest Connection (RFCx)](https://rfcx.org/) est un projet innovant qui place des smartphones modifi√©s dans les arbres, enregistre des donn√©es audio, puis utilise des mod√®les pour identifier les diff√©rentes esp√®ces pr√©sentes dans la zone. Cela permet de surveiller la biodiversit√© et de d√©tecter les activit√©s ill√©gales comme l'exploitation foresti√®re en temps r√©el.\n",
        "\n",
        "<div align=\"center\">\n",
        "    <img src=\"https://www.huawei.com/~/media/CORPORATE/Images/case-studies/case1/photo-grid.jpg\" alt=\"Configuration de Rainforest connection\" width=\"600\">\n",
        "</div>\n",
        "\n",
        "<div align=\"center\">\n",
        "    <img src=\"https://cdn.ttgtmedia.com/visuals/LeMagIT/Forest1.png\" alt=\"Audio de Rainforest connection\" width=\"600\">\n",
        "</div>\n",
        "\n",
        "\n",
        "\n",
        "[Project CETI](https://www.projectceti.org/) (Cetacean Translation Initiative) utilise l'IA pour analyser et d√©coder les sons des baleines afin de comprendre leur communication et leur comportement.\n",
        "\n",
        "\n",
        "<div align=\"center\">\n",
        "    <img src=\"https://i0.wp.com/www.josephdelpreto.com/wp-content/uploads/2023/09/Project-CETI_s-Approach-_-Illustration-%C2%A9-2023-Alex-Boersma.jpg?resize=1024%2C912\" alt=\"Baleine CETI\" width=\"600\">\n",
        "</div>\n",
        "\n",
        "\n",
        "Un concours Zindi appel√© [Turtle Recall](https://zindi.africa/competitions/turtle-recall-conservation-challenge) a mis les utilisateurs au d√©fi de construire un mod√®le capable d'identifier les tortues marines individuelles √† partir des motifs d'√©cailles sur leur t√™te, ce qui pourrait contribuer √† am√©liorer les efforts de conservation des tortues marines :\n",
        "\n",
        "<div align=\"center\">\n",
        "    <img src=\"https://lh3.googleusercontent.com/9J6DZgiuGyYr3N1DoJBmZMVpBkTlGOq19QUws7G2fbFcuHeIJKQ3plFh-R2xkxB1OpVaqZhcglM6hWWl5x7PuuxbtnDlIWlCgoCr0LGVM4S-loaj_Jc=w1232-rw\" alt=\"Rappel des tortues\" width=\"600\">\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q61C7IWMs5Up"
      },
      "source": [
        "**Sondage** : Levez la main, lequel de ces sous-domaines de l'IA pour la biologie trouvez-vous le plus int√©ressant ?\n",
        "1. üè• **Diagnostics m√©dicaux** üè•\n",
        "2. üíä **Pharmacie et d√©veloppement de m√©dicaments** üíä\n",
        "3. üß¨ **Biologie mol√©culaire** üß¨\n",
        "4. üå≥ **√âcologie et conservation** üå≥\n",
        "5. **Autre** (lequel ? :)\n",
        "\n",
        "**Question** : quelles autres initiatives int√©ressantes dans le domaine de l'IA en biologie connaissez-vous ?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uekgwzRTabu_"
      },
      "source": [
        "### Lectures compl√©mentaires\n",
        "\n",
        "Ces exemples ne sont pas exhaustifs et visent simplement √† vous donner un aper√ßu de certaines applications actuelles de l'IA en biologie. Si vous souhaitez en savoir plus sur ce domaine, voici quelques ressources int√©ressantes √† lire :\n",
        "\n",
        "- Un article de revue de *Nature Communications* de 2022 intitul√© [\"Current progress and open challenges for applying deep learning across the biosciences\"](https://www.nature.com/articles/s41467-022-29268-7)\n",
        "- Un article de revue un peu plus ancien (2018) intitul√© [‚ÄúOpportunities and obstacles for deep learning in biology and medicine‚Äù](https://royalsocietypublishing.org/doi/10.1098/rsif.2017.0387). Celui-ci a √©t√© cit√© plus de 2 000 fois !\n",
        "- [\"Deep Learning for the Life Sciences\"](https://www.oreilly.com/library/view/deep-learning-for/9781492039822/), un livre d'O'Reilly de 2019, qui fournit des informations pratiques et des applications du deep learning en g√©nomique, en chimie et en bio-informatique.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3U85xKMaf4f"
      },
      "source": [
        "## 2. Introduction √† l'ADN\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsoawR4YWZuu"
      },
      "source": [
        "Nous esp√©rons que cette introduction vous a suffisamment enthousiasm√© pour les applications de l'apprentissage profond en biologie ! Pour le reste de cette s√©ance pratique, nous allons nous plonger nous-m√™mes dans le travail d'IA appliqu√© √† la biologie, en nous concentrant sur le sujet de l'ADN.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPg62NUYVCYx"
      },
      "source": [
        "<div align=\"center\">\n",
        "    <img src=\"https://i.pinimg.com/originals/c7/90/76/c79076215950e968828f663e1b69fe67.gif\" alt=\"DNA gif\" width=\"200\">\n",
        "</div>\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-2h_qSbbCVb"
      },
      "source": [
        "**L'ADN est la mol√©cule de l'h√©r√©dit√©, la base de toute vie telle que nous la connaissons.**\n",
        "\n",
        "Sa structure a √©t√© d√©couverte pour la premi√®re fois en 1953, marquant un moment crucial dans les sciences biologiques. La premi√®re √©bauche du g√©nome humain a √©t√© publi√©e en 2001, jetant les bases de la g√©nomique moderne.\n",
        "\n",
        "Mais ces dates sont assez r√©centes, et bien que nous connaissions maintenant une partie du \"quoi\" du g√©nome, nous sommes tr√®s loin de conna√Ætre le \"comment\" de son fonctionnement r√©el.\n",
        "\n",
        "Par exemple, nous savons que l'ADN est compos√© de 4 \"lettres\" diff√©rentes, √† savoir A (ad√©nine), C (cytosine), G (guanine) et T (thymine) et que le g√©nome humain est compos√© de 3,2 milliards de lettres qui sont r√©parties sur 23 paires de chromosomes. L'ADN est compact√© de diff√©rentes mani√®res afin de tenir dans le noyau de la cellule :\n",
        "\n",
        "<div align=\"center\">\n",
        "    <img src=\"https://miro.medium.com/v2/resize:fit:1400/1*EUKrGpPzUAwp2sOOPZOcqA.jpeg\" alt=\"DNA text\" width=\"400\">\n",
        "</div>\n",
        "\n",
        "Si nous devions ouvrir le \"livre\" du g√©nome humain, nous verrions quelque chose comme ceci :\n",
        "\n",
        "<div align=\"center\">\n",
        "    <img src=\"https://cms.wellcome.org/sites/default/files/styles/image_full_hi/public/WI_C0035768_GenomeEditing_20150902_News_600x600.jpg?itok=FCedpedU\" alt=\"DNA text\" width=\"400\">\n",
        "</div>\n",
        "\n",
        "**Ceci peut √™tre tr√®s difficile √† interpr√©ter**. Et il y a beaucoup d'ADN √† interpr√©ter - assez pour remplir une biblioth√®que s'il √©tait imprim√© dans des volumes de livres :\n",
        "\n",
        "<div align=\"center\">\n",
        "    <img src=\"https://live.staticflickr.com/3265/2569126918_b68047a65b_b.jpg\" alt=\"DNA bookcase\" width=\"400\">\n",
        "</div>\n",
        "\n",
        "Parmi les principales questions ouvertes que nous nous posons sur l'ADN, citons :\n",
        "- Que font les 3,2 milliards de lettres du g√©nome humain ? Sont-elles toutes biologiquement fonctionnelles ?\n",
        "- Comment chaque cellule du corps humain peut-elle avoir exactement le m√™me g√©nome, mais avoir des fonctions tr√®s diff√©rentes ? Par exemple, pensez √† la diff√©rence entre un neurone et une cellule musculaire.\n",
        "- Nous savons que seulement 2 % environ de l'ADN du g√©nome code pour des prot√©ines, √† quoi servent les 98 % restants ?\n",
        "- Comment la variation g√©n√©tique conduit-elle √† la maladie ou aux diff√©rences que nous observons entre les individus ?\n",
        "\n",
        "Pour r√©sumer :\n",
        "\n",
        "***Le g√©nome humain peut √™tre consid√©r√© comme un tr√®s long livre dont les mots sont compos√©s des lettres A, T, C et G. Les mod√®les de deep learning sont tr√®s prometteurs pour la compr√©hension du g√©nome en raison de leur capacit√© √† saisir le signal dans des donn√©es volumineuses, complexes et potentiellement bruyantes.***\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUZs124vaoAc"
      },
      "source": [
        "## Mod√®les de langage ADN\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1XSYCABa1pV"
      },
      "source": [
        "## Mod√®les de langage ADN\n",
        "\n",
        "**Les mod√®les de langage ADN (LMs)** sont tr√®s similaires aux mod√®les de langage de grande taille que vous connaissez peut-√™tre, tels que ChatGPT, Gemini, Claude, etc. Au lieu d'√™tre entra√Æn√©s sur de grandes quantit√©s de texte en langage naturel, les LMs d'ADN sont entra√Æn√©s sur de grandes quantit√©s de s√©quences d'ADN.\n",
        "\n",
        "De nombreux LLMs et LMs d'ADN sont entra√Æn√©s en **masquant** de mani√®re al√©atoire certains jetons dans le texte, puis en demandant au mod√®le de pr√©dire ce qu'est le jeton¬†:\n",
        "\n",
        "<div align=\"center\">\n",
        "<a href=\"https://ibb.co/M9d9GM0\"><img src=\"https://i.ibb.co/25J5sg4/Screenshot-2024-07-23-at-22-18-57.png\" alt=\"Screenshot-2024-07-23-at-22-18-57\" width=\"800\" border=\"0\"></a>\n",
        "</div>\n",
        "\n",
        "De la m√™me mani√®re que les LLMs acqui√®rent une compr√©hension du langage qui peut ensuite √™tre utile pour de nombreuses t√¢ches en aval, les mod√®les de langage ADN peuvent capturer les sch√©mas et les structures complexes au sein de l'ADN, ce qui les rend pr√©cieux pour diverses t√¢ches g√©nomiques en aval telles que l'analyse des mutations et la compr√©hension des √©l√©ments r√©gulateurs¬†:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5nhVXVvQfsb"
      },
      "source": [
        "## Quelques mod√®les de langage ADN populaires\n",
        "\n",
        "Tout comme les LLMs ont connu un succ√®s massif, de plus en plus de personnes s'int√©ressent √† l'entra√Ænement de mod√®les de langage ADN. Parmi les plus c√©l√®bres, citons :\n",
        "\n",
        "- [DNABERT](https://academic.oup.com/bioinformatics/article/37/15/2112/6128680) (2021) - DNABERT adapte le mod√®le BERT, qui a connu un grand succ√®s en PNL (NLP), pour comprendre les s√©quences d'ADN.\n",
        "- [HyenaDNA](https://arxiv.org/abs/2306.15794) (2023) - Sp√©cialis√© dans les longues s√©quences d'ADN, avec des contextes allant jusqu'√† 1¬†million de jetons au niveau du nucl√©otide unique.\n",
        "- [Nucleotide Transformer](https://www.biorxiv.org/content/10.1101/2023.01.11.523679v1) (2023) - une architecture bas√©e sur un transformateur sp√©cifiquement con√ßue pour les s√©quences de nucl√©otides.\n",
        "\n",
        "Certaines personnes ont √©galement affin√© des LLMs en langage naturel existants sur des s√©quences d'ADN, par exemple [Mistral-DNA](https://github.com/raphaelmourad/Mistral-DNA).\n",
        "\n",
        "Pour ce TP, nous utiliserons le mod√®le Nucleotide Transformer\n",
        "(NT) car il est assez performant, populaire et facilement disponible sur la [plateforme Hugging Face ü§ó](https://huggingface.co/).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi3kRTr4cFVv"
      },
      "source": [
        "## Le mod√®le Nucleotide Transformer (NT)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI4e0ondcGzl"
      },
      "source": [
        "Nucleotide Transformer a √©t√© entra√Æn√© sur 3 202 g√©nomes humains divers, ainsi que sur 850 g√©nomes provenant d'un large √©ventail d'esp√®ces. Le mod√®le g√©n√®re des repr√©sentations transf√©rables et contextuelles de s√©quences d'ADN.\n",
        "\n",
        "Voici quelques d√©tails suppl√©mentaires sur le mod√®le¬†:\n",
        "- NT est une architecture de transformateur √† encodeur uniquement, form√©e √† l'aide de l'approche BERT (masquage de parties de s√©quences d'ADN). Les s√©quences d'ADN ont √©t√© tokenis√©es en 6-mers.\n",
        "- Il s'agit d'un mod√®le non supervis√©, mais ses repr√©sentations seules √©galent ou surpassent les m√©thodes sp√©cialis√©es sur 11¬†t√¢ches de pr√©diction sur¬†18, telles que la pr√©diction de la pr√©sence de certains √©l√©ments r√©gulateurs connus sous le nom de promoteurs et d'amplificateurs dans un fragment d'ADN donn√©.\n",
        "- Les donn√©es d'entra√Ænement pour la version `nucleotide-transformer-v2-50m-multi-species` de NT ont √©t√© entra√Æn√©es sur un total de **174¬†milliards de nucl√©otides**, soit environ **29¬†milliards de jetons (tokens)**. Voici les statistiques par groupe d'organismes¬†:\n",
        "\n",
        "| Classe                | Nombre d'esp√®ces | Nombre de nucl√©otides (milliards) |\n",
        "| ---------------------| -------------------| --------------------------|\n",
        "| Bact√©ries            | 667                | 17,1                      |\n",
        "| Champignons           | 46                 | 2,3                       |\n",
        "| Invert√©br√©s          | 39                 | 20,8                      |\n",
        "| Protozoaires          | 10                 | 0,5                       |\n",
        "| Vert√©br√©s mammif√®res | 31                 | 69,8                      |\n",
        "| Autres vert√©br√©s      | 57                 | 63,4                      |\n",
        "\n",
        "Il existe d'autres versions plus volumineuses du mod√®le disponibles sur Hugging Face [ici](https://huggingface.co/collections/InstaDeepAI/nucleotide-transformer-65099cdde13ff96230f2e592). Nous utilisons ici un mod√®le relativement petit pour des raisons de vitesse.\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfpDwu0mbC2U"
      },
      "source": [
        "## Exploration des plongements d'ADN dans diff√©rentes esp√®ces\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SvGZ0yAUEor"
      },
      "source": [
        "Chargeons le mod√®le Nucleotide Transformer (NT) depuis HuggingFace et commen√ßons √† l'utiliser¬†!\n",
        "\n",
        "Nous avons d√©j√† charg√© le tokenizer et le mod√®le dans la premi√®re cellule du notebook. Ce sont ces deux objets¬†:\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hisjeBWMhQr"
      },
      "outputs": [],
      "source": [
        "type(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3Pc0E_lMjk_"
      },
      "outputs": [],
      "source": [
        "type(language_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlhntuz2FKOT"
      },
      "source": [
        "    \n",
        "Voyons ce que le mod√®le a appris sur l'ADN de diff√©rentes esp√®ces. Nous pouvons prendre des s√©quences d'ADN al√©atoires provenant de diff√©rentes esp√®ces, utiliser le mod√®le pour extraire une repr√©sentation **embedding** de l'ADN, et voir si les esp√®ces similaires ont tendance √† avoir un ADN avec des repr√©sentations similaires.\n",
        "\n",
        "Cr√©ons une liste d'esp√®ces qui nous int√©ressent¬†:\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVw2zyrjuAJ7"
      },
      "outputs": [],
      "source": [
        "organismes = [\n",
        "    'Homo sapiens',  # Humain\n",
        "    'Pan troglodytes',  # Chimpanz√©\n",
        "    'Pan paniscus',     # Bonobo\n",
        "    'Gorilla gorilla',  # Gorille\n",
        "    'Tursiops truncatus',  # Dauphin (√† gros nez)\n",
        "    'Hydrochoerus hydrochaeris',  # Capybara\n",
        "    'Escherichia coli',  # Bact√©rie E. coli\n",
        "    'Lactobacillus acidophilus',  # Bact√©rie probiotique commune\n",
        "    'Salmonella enterica',  # Pathog√®ne d'origine alimentaire courant\n",
        "    'Pseudomonas aeruginosa',  # Bact√©rie pr√©sente dans le sol et l'eau\n",
        "]\n",
        "\n",
        "print(len(organismes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgTtxzq_V333"
      },
      "source": [
        "On peut utiliser la biblioth√®que Python `Entrez` pour effectuer une recherche dans la base de donn√©es pour une cha√Æne d'ADN al√©atoire pour un organisme donn√©¬†:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v884-yBoV81G"
      },
      "outputs": [],
      "source": [
        "organism = 'Homo sapiens'\n",
        "gene = 'BRCA1'  # Nom de g√®ne exemple.\n",
        "\n",
        "Entrez.email = \"your.email@example.com\"  # Requis. Peut √™tre un espace r√©serv√©.\n",
        "\n",
        "# Recherche des enregistrements d'ADN pour l'organisme.\n",
        "query = f'({gene}[Gene Name]) AND {organism}[Organism] AND \"RefSeq\"[filter]'\n",
        "handle = Entrez.esearch(db='nucleotide', term=query, retmax=10)\n",
        "record = Entrez.read(handle)\n",
        "handle.close()\n",
        "\n",
        "# R√©cup√©rer un enregistrement al√©atoire.\n",
        "np.random.seed(42)\n",
        "random_record_id = np.random.choice(record['IdList'])\n",
        "\n",
        "# Lire l'ADN.\n",
        "handle = Entrez.efetch(\n",
        "    db='nucleotide', id=random_record_id, rettype='fasta', retmode='text')\n",
        "seq_record = SeqIO.read(handle, 'fasta')\n",
        "\n",
        "print(seq_record)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c9OD88UWcbD"
      },
      "source": [
        "On peut facilement extraire la cha√Æne d'ADN de cette entr√©e :\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NE3WVQZAWUzo"
      },
      "outputs": [],
      "source": [
        "dna_sequence = str(seq_record.seq)\n",
        "dna_sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irKR4ijrXPeV"
      },
      "source": [
        "Le mod√®le NT peut √™tre utilis√© pour calculer une repr√©sentation num√©rique de la signification de cette s√©quence d'ADN. Nous allons simplement passer la s√©quence d'ADN en entr√©e, la tokeniser, et extraire les activations de la derni√®re couche cach√©e du mod√®le¬†:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91-IP-4CXd4Z"
      },
      "outputs": [],
      "source": [
        "#¬†Tokenisation de la s√©quence d'ADN.\n",
        "max_length = tokenizer.model_max_length\n",
        "\n",
        "token_ids = tokenizer.batch_encode_plus(\n",
        "  [dna_sequence], return_tensors='pt',\n",
        "  padding='max_length', max_length=max_length,\n",
        "  truncation=True)['input_ids']\n",
        "\n",
        "token_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIPxAnTKYi_j"
      },
      "source": [
        "Vous pouvez voir que la s√©quence d'ADN a √©t√© tokenis√©e et compl√©t√©e (padded) avec le token `1` jusqu'√† la longueur maximale de 2048¬†:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkbnezMnYd03"
      },
      "outputs": [],
      "source": [
        "len(token_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psxQ5Ib5Yqax"
      },
      "outputs": [],
      "source": [
        "token_ids[0][-50:]  # Afficher les 50 derniers jetons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUHpbYFoY2CQ"
      },
      "source": [
        "Voyons maintenant la sortie du mod√®le √©tant donn√© cette entr√©e d'ADN¬†:\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOPWLYQ9X7Hp"
      },
      "outputs": [],
      "source": [
        "masque_attention = token_ids != tokenizer.pad_token_id\n",
        "\n",
        "torch_outs = language_model(\n",
        "  token_ids,\n",
        "  attention_mask=masque_attention,\n",
        "  encoder_attention_mask=masque_attention,\n",
        "  output_hidden_states=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKza0f1jZFDd"
      },
      "source": [
        "On peut voir que 13 sorties d'√©tats cach√©s diff√©rentes sont pr√©sentes, repr√©sentant les sorties de 13 couches diff√©rentes dans le mod√®le¬†:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARjvBGUAY6Gg"
      },
      "outputs": [],
      "source": [
        "len(torch_outs['hidden_states'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N92L57BIZOiu"
      },
      "source": [
        "Prenons le dernier √©tat cach√© √† l'index `-1` car il est susceptible d'√™tre informatif (mais peut-√™tre pas de mani√®re optimale pour chaque t√¢che - nous pourrions essayer l'avant-dernier √©tat cach√©, ou le troisi√®me √† partir de la fin, etc.) :\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTruDvORZYM7"
      },
      "outputs": [],
      "source": [
        "embeddings = torch_outs['hidden_states'][-1].detach()\n",
        "embeddings = np.squeeze(embeddings.numpy())\n",
        "embeddings.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt6PoMHoZhrG"
      },
      "source": [
        "On peut voir que le plongement est une matrice de forme 2048 par 512. C'est une grande matrice numpy¬†!\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-_x-wwjZust"
      },
      "outputs": [],
      "source": [
        "embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YTHUDbdZxcy"
      },
      "source": [
        "Au sein de cette large matrice de nombres, le mod√®le a captur√© un certain sens de la signification de la cha√Æne d'ADN.\n",
        "\n",
        "Rappelons que notre cha√Æne d'ADN avait une longueur de 2048 ‚Äì cela signifie que chaque position a son propre vecteur de plongement (embeddings) de longueur 512 qui est contextuel.\n",
        "\n",
        "Nous pourrions visualiser cette matrice de nombres, mais cela en soi ne serait pas tr√®s significatif :\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCj4Bu6TaGbK"
      },
      "outputs": [],
      "source": [
        "plt.imshow(embeddings)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMqR4K-baXns"
      },
      "source": [
        "Une fa√ßon courante de r√©sumer un plongement comme celui-ci est de calculer le **plongement moyen**¬†: nous pouvons prendre la moyenne sur l‚Äôaxe spatial et obtenir un plongement de longueur 512 qui repr√©sente la s√©quence d‚ÄôADN enti√®re.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KWL7QyDbN4A"
      },
      "outputs": [],
      "source": [
        "# D√©placer l'axe pour que le broadcasting fonctionne.\n",
        "masque_attention = np.moveaxis(masque_attention.numpy(), 0, -1)\n",
        "\n",
        "# Calcul du plongement (embeddings) moyen.\n",
        "mean_embeddings = np.sum(\n",
        "    masque_attention * embeddings, axis=0) / np.sum(masque_attention)\n",
        "\n",
        "plt.plot(mean_embeddings, color='grey')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0obDhoSbsF9"
      },
      "source": [
        "**C'est pratique de pouvoir condenser une s√©quence d'ADN en 512 nombres comme ceci, mais c'est encore difficile de vraiment savoir ce que ces nombres signifient.**\n",
        "\n",
        "La valeur des plongements (embeddings) de s√©quences se r√©v√®le vraiment lorsque vous les **comparez les uns aux autres**. Donc, √©crivons la fonction `fetch_random_dna` qui va extraire des s√©quences d'ADN al√©atoires pour une esp√®ce donn√©e¬†:\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-Wor2NYVwuS"
      },
      "outputs": [],
      "source": [
        "def fetch_random_dna(\n",
        "  organism: str,\n",
        "  min_length: int,\n",
        "  max_length: int,\n",
        "  num_sequences: int,\n",
        "  max_attempts: int = 50) -> list[str]:\n",
        "  \"\"\"R√©cup√®re un certain nombre de s√©quences d'ADN d'une longueur donn√©e pour une esp√®ce.\"\"\"\n",
        "  # Recherche des entr√©es nucl√©otidiques pour l'organisme comme nous l'avons fait pr√©c√©demment.\n",
        "  handle = Entrez.esearch(\n",
        "      db='nucleotide', term=f'{organism}[Organism]', retmax=max_attempts)\n",
        "  record = Entrez.read(handle)\n",
        "  handle.close()\n",
        "  if not record['IdList']:\n",
        "    return []\n",
        "\n",
        "  # Nous pouvons collecter nos s√©quences d'ADN dans cette liste.\n",
        "  sequences = []  # (s√©quences)\n",
        "  attempts = 0  # (tentatives)\n",
        "\n",
        "  while len(sequences) < num_sequences and attempts < max_attempts:\n",
        "    random_record_id = random.choice(record['IdList'])\n",
        "    handle = Entrez.efetch(\n",
        "        db='nucleotide', id=random_record_id, rettype='fasta', retmode='text')\n",
        "    try:\n",
        "      seq_record = SeqIO.read(handle, 'fasta')\n",
        "      handle.close()\n",
        "\n",
        "      if len(seq_record.seq) >= min_length:\n",
        "        seq = str(seq_record.seq) # (seq)\n",
        "        if len(seq) > max_length:\n",
        "          seq = seq[:max_length]\n",
        "        sequences.append(seq)\n",
        "\n",
        "    # G√®re le cas o√π aucun enregistrement FASTA valide n'a √©t√© trouv√©.\n",
        "    except ValueError:\n",
        "      handle.close()\n",
        "    attempts += 1\n",
        "\n",
        "  return sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-F4OQESebs4"
      },
      "source": [
        "Utilisons cela pour r√©cup√©rer une courte s√©quence d'ADN pour l'homme :\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xbuwa-8eWR-"
      },
      "outputs": [],
      "source": [
        "fetch_random_dna(\n",
        "    organism='Homo sapiens', min_length=10, max_length=50, num_sequences=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeCb7wbGeiN-"
      },
      "source": [
        "Maintenant, on peut facilement l'utiliser pour r√©cup√©rer des s√©quences d'ADN pour les organismes dans notre liste ci-dessus. Le code pour faire cela ressemblerait √† ceci :\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXHNINCZeUAS"
      },
      "outputs": [],
      "source": [
        "NUM_SEQUENCES = 1\n",
        "MIN_LENGTH = 100\n",
        "MAX_LENGTH = 1000\n",
        "random.seed(42)\n",
        "\n",
        "# (first_organisms) : premiers organismes\n",
        "first_organisms = organismes[0:3]\n",
        "\n",
        "print(f'Fetching {NUM_SEQUENCES} random DNA sequences of min length '\n",
        "      f'{MIN_LENGTH} and max length {MAX_LENGTH} for {len(first_organisms)} '\n",
        "      'organisms...\\n')\n",
        "\n",
        "dna_sequences_small = []\n",
        "# (organism_labels) : √©tiquettes des organismes\n",
        "organism_labels = []\n",
        "\n",
        "# (organism) : organisme\n",
        "for organism in tqdm.tqdm(first_organisms, desc='Organisms'):\n",
        "  print(organism, flush=True)\n",
        "  # (sequences) : s√©quences\n",
        "  sequences = fetch_random_dna(\n",
        "      organism, min_length=MIN_LENGTH, max_length=MAX_LENGTH,\n",
        "      num_sequences=NUM_SEQUENCES)\n",
        "  dna_sequences_small += sequences\n",
        "  organism_labels += [organism] * len(sequences)\n",
        "\n",
        "# (sequence) : s√©quence\n",
        "dna_sequences_small = pd.DataFrame({'sequence': dna_sequences_small, 'organism': organism_labels})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIs-VYPDgRKE"
      },
      "source": [
        "Mais cela prend quelques minutes √† s'ex√©cuter si nous voulons par exemple 20 s√©quences d'ADN pour chacun des 10 organismes, donc par souci de rapidit√©, nous avons pr√©-r√©cup√©r√© certaines s√©quences pour plus de commodit√©¬†:\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNrT7f6y1yv3"
      },
      "outputs": [],
      "source": [
        "dna_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMzlFGizQbor"
      },
      "source": [
        "Nous pouvons nous appuyer sur notre code pr√©c√©dent pour extraire les plongements moyens des s√©quences d'ADN :\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-1hLFeQ3Gwp"
      },
      "outputs": [],
      "source": [
        "def _compute_mean_sequence_embeddings(\n",
        "  dna_sequences: list[str],\n",
        "  tokenizer: AutoTokenizer,\n",
        "  model: AutoModelForMaskedLM):\n",
        "\n",
        "  max_length = tokenizer.model_max_length\n",
        "  tokens_ids = tokenizer.batch_encode_plus(\n",
        "    dna_sequences, return_tensors=\"pt\", padding=\"max_length\",\n",
        "    max_length=max_length)[\"input_ids\"]\n",
        "\n",
        "  # Calcul des plongements.\n",
        "  attention_mask = tokens_ids != tokenizer.pad_token_id\n",
        "\n",
        "  # D√©placement du mod√®le et des tenseurs vers le GPU.\n",
        "  model = model.to('cuda')\n",
        "  tokens_ids = tokens_ids.to('cuda')\n",
        "  attention_mask = attention_mask.to('cuda')\n",
        "\n",
        "  # Par d√©faut, PyTorch conserve le graphe de calcul pour la passe arri√®re, mais cela\n",
        "  # remplit la RAM et nous n'en avons pas besoin, nous le d√©sactivons donc avec torch.no_grad().\n",
        "  with torch.no_grad():\n",
        "    torch_outs = model(\n",
        "      tokens_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      encoder_attention_mask=attention_mask,\n",
        "      output_hidden_states=True,\n",
        "    )\n",
        "\n",
        "  # Calcul des plongements de s√©quences.\n",
        "  embeddings = torch_outs['hidden_states'][-1].detach().cpu()\n",
        "\n",
        "  # Ajout d'une dimension de plongement.\n",
        "  attention_mask_cpu = torch.unsqueeze(attention_mask.cpu(), dim=-1)\n",
        "\n",
        "  # Calcul des plongements moyens par s√©quence\n",
        "  mean_sequence_embeddings = torch.sum(\n",
        "    attention_mask_cpu * embeddings, axis=-2) / torch.sum(attention_mask_cpu, axis=1)\n",
        "\n",
        "  return mean_sequence_embeddings.numpy()\n",
        "\n",
        "\n",
        "def compute_mean_sequence_embeddings(\n",
        "    dna_sequences: list[str],\n",
        "    tokenizer: AutoTokenizer,\n",
        "    model: AutoModelForMaskedLM,\n",
        "    batch_size: int = 20) -> np.ndarray:\n",
        "  \"\"\"Calcule les plongements moyens de s√©quences pour une liste de cha√Ænes d'ADN.\"\"\"\n",
        "  all_mean_embeddings = []\n",
        "\n",
        "  # (batch_sequences: lots de s√©quences, batch_mean_embeddings: plongements moyens des lots)\n",
        "  for i in tqdm.tqdm(range(0, len(dna_sequences), batch_size)):\n",
        "    batch_sequences = dna_sequences[i:i+batch_size]\n",
        "    batch_mean_embeddings = _compute_mean_sequence_embeddings(\n",
        "        batch_sequences, tokenizer, model)\n",
        "    all_mean_embeddings.extend(batch_mean_embeddings)\n",
        "\n",
        "  return np.vstack(all_mean_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sF77cUxYn1WQ"
      },
      "outputs": [],
      "source": [
        "embeddings = compute_mean_sequence_embeddings(\n",
        "    dna_sequences['sequence'], tokenizer, language_model, batch_size=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AyrRWPrQxaJ"
      },
      "source": [
        "Cela nous donne un encodage de longueur 512 pour chacune des 200 cha√Ænes d'ADN¬†:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieeTRVEAQwOO"
      },
      "outputs": [],
      "source": [
        "embeddings.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qV0ZDnTSQ2Uy"
      },
      "source": [
        "Ce serait formidable de pouvoir visualiser ces donn√©es. Mais comme les humains ne peuvent pas vraiment visualiser des choses dans un espace √† 512 dimensions, utilisons d'abord une technique de r√©duction de dimensionnalit√© telle que tSNE pour projeter les donn√©es sur 2 dimensions. Cela donne 2 nombres pour chaque s√©quence d'ADN originale qui capturent encore une certaine notion de sens dans l'ADN :\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6i1lalSt3DUg"
      },
      "outputs": [],
      "source": [
        "tsne = TSNE(n_components=2, learning_rate='auto', random_state=0)\n",
        "embeddings_tsne = tsne.fit_transform(embeddings)\n",
        "\n",
        "# (embeddings_tsne_df) : DataFrame des embeddings apr√®s tSNE\n",
        "embeddings_tsne_df = pd.DataFrame(\n",
        "    embeddings_tsne, columns=['first_dim', 'second_dim'])\n",
        "\n",
        "# (organism) : Organisme\n",
        "embeddings_tsne_df['organism'] = dna_sequences['organism']\n",
        "embeddings_tsne_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCMrzbZU3FMR"
      },
      "source": [
        "# On peut √©tiqueter chaque token avec son esp√®ce ou une √©tiquette plus g√©n√©rale, comme \"animal\" ou \"plante\".\n",
        "    # Cela nous permet de voir si des s√©quences similaires provenant d'esp√®ces similaires se regroupent.\n",
        "    # On peut ensuite redessiner le graphique et le colorer par √©tiquette :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FSSR3h53MPG"
      },
      "outputs": [],
      "source": [
        "labels = {\n",
        "    'Homo sapiens': 'animal',\n",
        "    'Pan paniscus': 'animal',\n",
        "    'Pan troglodytes': 'animal',\n",
        "    'Tursiops truncatus': 'animal',\n",
        "    'Hydrochoerus hydrochaeris': 'animal',\n",
        "    'Escherichia coli': 'bact√©rie',\n",
        "    'Pseudomonas aeruginosa': 'bact√©rie',\n",
        "    'Lactobacillus acidophilus': 'bact√©rie',\n",
        "    'Salmonella enterica': 'bact√©rie',\n",
        "    }\n",
        "\n",
        "embeddings_tsne_df['label'] = embeddings_tsne_df['organism'].map(labels)\n",
        "\n",
        "ax = sns.scatterplot(data=embeddings_tsne_df,\n",
        "                x='first_dim',\n",
        "                y='second_dim',\n",
        "                hue='label', color=None,\n",
        "                s=200, alpha=0.7, palette='Set2')\n",
        "\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "manXg5mkfRqU"
      },
      "source": [
        "Il semble que, bien que les s√©quences animales et bact√©riennes aient tendance √† occuper des parties quelque peu diff√©rentes de l'espace d'incorporation, il existe certainement beaucoup de chevauchements, ce qui sugg√®re que les g√©nomes de l'arbre de vie partagent de nombreuses similitudes¬†!\n",
        "\n",
        "**Question¬†**: Est-ce ce √† quoi vous vous attendiez¬†?\n",
        "\n",
        "Si vous souhaitez en savoir plus sur les g√©nomes animaux et bact√©riens, voici quelques faits amusants¬†:\n",
        "- ***Similitudes***¬†:\n",
        "  - **Code g√©n√©tique de base**¬†: les g√©nomes animaux et bact√©riens utilisent le m√™me code g√©n√©tique, avec des s√©quences d'ADN compos√©es des quatre m√™mes nucl√©otides¬†: ad√©nine (A), cytosine (C), guanine (G) et thymine (T).\n",
        "  - **G√®nes conserv√©s**¬†: De nombreux g√®nes fondamentaux impliqu√©s dans des processus essentiels, tels que la r√©plication de l'ADN, la transcription et la traduction, sont conserv√©s chez les animaux et les bact√©ries.\n",
        "- ***Diff√©rences***¬†:\n",
        "  - **Taille du g√©nome**¬†: les g√©nomes animaux sont g√©n√©ralement beaucoup plus gros (les humains ont 3,2¬†milliards de bases d'ADN) tandis que les g√©nomes bact√©riens sont plus petits (de quelques centaines de milliers √† quelques millions).\n",
        "  - **Chromosomes**¬†: les animaux ont plusieurs chromosomes lin√©aires, tandis que les bact√©ries ont g√©n√©ralement un seul chromosome circulaire.\n",
        "  - **Densit√© des g√®nes**¬†: les g√©nomes bact√©riens sont plus denses en g√®nes, tandis que les g√©nomes animaux sont plus rares et comportent plus d'√©l√©ments r√©gulateurs.\n",
        "  - **Structure des g√®nes**¬†: les g√®nes animaux contiennent souvent des introns (r√©gions non codantes au sein des g√®nes) contrairement aux g√®nes bact√©riens en g√©n√©ral.\n",
        "\n",
        "**Question :** Lesquelles de ces diff√©rences pourraient √™tre captur√©es par les embeddings mentionn√©s ci-dessus ?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZnCLa1xHjTQ"
      },
      "source": [
        "**T√¢che**¬†:\n",
        "- Essayez de saisir des s√©quences d'ADN pour d'autres esp√®ces, par exemple des esp√®ces v√©g√©tales. Voici quelques noms scientifiques de plantes¬†:\n",
        "```python\n",
        " plants = [\n",
        "  'Oryza sativa',  # Riz\n",
        "  'Vitis vinifera',  # Raisin\n",
        "  'Rosa chinensis',  # Rose\n",
        "  'Musa acuminata',  # Banane\n",
        "  'Solanum lycopersicum', # Tomate\n",
        " ]\n",
        " ```\n",
        "- Dans quelle mesure le nuage de points est-il sensible aux changements de germe al√©atoire ou aux autres param√®tres¬†? Essayez une technique de r√©duction de dimensionnalit√© diff√©rente telle que UMAP au lieu de tSNE. Le nuage de points est-il diff√©rent¬†?\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z19k8a3Pc3Mo"
      },
      "source": [
        "## 3. R√©glage fin d'un mod√®le de langage ADN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAqyowcEIr9z"
      },
      "source": [
        "\n",
        "Dans cette derni√®re section, nous allons adapter notre mod√®le de langage ADN √† une nouvelle t√¢che par **r√©glage fin** (fine-tuning).\n",
        "\n",
        "### Qu'est-ce que le r√©glage fin ?\n",
        "Le r√©glage fin est le processus qui consiste √† prendre un **mod√®le pr√©-entra√Æn√©** et √† y apporter de l√©g√®res modifications afin qu'il puisse effectuer une nouvelle t√¢che sp√©cialis√©e.\n",
        "\n",
        "Au lieu d'entra√Æner un mod√®le √† partir de z√©ro, ce qui peut prendre beaucoup de temps et n√©cessiter beaucoup de donn√©es, nous commen√ßons par un mod√®le qui comprend d√©j√† certains concepts g√©n√©raux. Nous l'entra√Ænons ensuite sur un ensemble de donn√©es plus petit et sp√©cifique √† la t√¢che.\n",
        "\n",
        "Le **pr√©-entra√Ænement suivi d'un r√©glage fin** est un mod√®le g√©n√©ral dans le domaine du ML. Voici quelques exemples tir√©s du langage naturel et du langage ADN :\n",
        "\n",
        "\n",
        "<a href=\"https://ibb.co/tpd50VH\"><img src=\"https://i.ibb.co/CKrFjRw/ML-for-bio-06.png\" alt=\"NLP vs DNA\" border=\"0\" width=\"400\"></a>\n",
        "\n",
        "\n",
        "### Le probl√®me biologique\n",
        "\n",
        "--> **Nous allons entra√Æner un mod√®le pour pr√©dire si une cha√Æne donn√©e de 200 bases d'ADN va se lier √† un facteur de transcription donn√©**.\n",
        "\n",
        "Les facteurs de transcription (FT) sont des prot√©ines sp√©ciales qui se lient √† l'ADN et jouent un r√¥le crucial dans l'activation ou la d√©sactivation des g√®nes. Ils sont essentiels car ils contr√¥lent l'expression des g√®nes, qui √† son tour affecte le fonctionnement, le d√©veloppement et la r√©ponse des cellules √† leur environnement. Par exemple, ils peuvent d√©terminer si une cellule devient une cellule musculaire, un neurone ou une cellule cutan√©e.\n",
        "\n",
        "Voici une image d'un facteur de transcription (en violet) se liant √† une certaine r√©gion de l'ADN (surlign√©e en jaune) :\n",
        "\n",
        "<div align=\"center\">\n",
        "    <img src=\"https://www.nichd.nih.gov/sites/default/files/2022-05/TranscriptionFactor-400px.jpg\" alt=\"DNA TF binding\" width=\"400\">\n",
        "</div>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Chaque facteur de transcription a une certaine **pr√©f√©rence de liaison** - il pr√©f√®re se lier √† une s√©quence sp√©cifique de bases d'ADN et pas √† d'autres. Cela est d√ª au fait que les formes 3D du FT et de la r√©gion de l'ADN peuvent bien s'assembler ou non.\n",
        "\n",
        "L'homme poss√®de plus de 1 000 facteurs de transcription. Nous allons nous int√©resser √† un facteur de transcription sp√©cifique appel√© CTCF, qui a tendance √† se lier √† des s√©quences similaires √† CCACCAGGGGGCGC (avec une certaine variation possible √† certaines positions).\n",
        "\n",
        "Voici le probl√®me de pr√©diction en termes visuels :\n",
        "\n",
        "\n",
        "- Pour une cha√Æne sp√©cifique de 200 paires de bases d'ADN, nous voulons pr√©dire la probabilit√© qu'un **facteur de transcription** donn√© se lie dans cette r√©gion.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFxmnixIOSad"
      },
      "source": [
        "## Le jeu de donn√©es\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcMjRbwISHrZ"
      },
      "source": [
        "Voici √† quoi ressemble le jeu de donn√©es que nous allons utiliser¬†:\n",
        "\n",
        "<a href=\"https://ibb.co/1ZbY3SF\"><img src=\"https://i.ibb.co/PxtsRSq/ML-for-bio-05.png\" alt=\"dataset description\" border=\"0\"></a>\n",
        "\n",
        "La t√¢che est une **t√¢che de classification binaire** ‚Äì √©tant donn√© 200¬†bases d'ADN, nous pr√©disons s'il se liera √† un facteur de transcription sp√©cifique appel√© CTCF. Le CTCF est en fait un facteur de transcription particuli√®rement int√©ressant, car il est impliqu√© dans l‚Äô**architecture du g√©nome**, c'est-√†-dire le repliement 3D √©labor√© du g√©nome en compartiments sp√©cifiques.\n",
        "\n",
        "Le probl√®me est inspir√© de l'une des t√¢ches d'√©valuation de ce r√©cent [pr√©-impression d'article de 2024](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10925287/), qui a tir√© le jeu de donn√©es de cet [article d'interpr√©tation de la g√©nomique de 2023](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10169356/)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igkX3Ur3iam3"
      },
      "source": [
        "#### Chargement du jeu de donn√©es.\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iu9RMDPZSb2N"
      },
      "source": [
        "Le jeu de donn√©es d'entra√Ænement a d√©j√† √©t√© construit pour vous¬†:\n",
        "- Nous avons 20¬†000 exemples d'entra√Ænement.\n",
        "- Chacun est un encodage (embedding) moyen de l'ADN qui a √©t√© extrait √† l'aide du mod√®le de langage NT.\n",
        "- La derni√®re colonne du dataframe est l'√©tiquette, indiquant si l'ADN se lie ou non √† la prot√©ine CTCF.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rM6jQWgISajU"
      },
      "outputs": [],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LypwXKfYTj01"
      },
      "source": [
        "En g√©n√©ral, on observe que les 2 classes sont assez √©quilibr√©es (repr√©sent√©es de mani√®re √©gale) dans le jeu de donn√©es d'entra√Ænement, ce qui signifie que nous n'aurons pas besoin de faire de r√©√©quilibrage ici¬†:\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Gx5qlSTTkW6"
      },
      "outputs": [],
      "source": [
        "train_df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL_5Ib2TS2bD"
      },
      "source": [
        "Si cela vous int√©resse, vous pouvez consulter le code qui a permis de g√©n√©rer ce jeu de donn√©es, mais vous n'avez pas besoin de l'ex√©cuter ici.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEqZwSkfi3BW"
      },
      "source": [
        "#### [Vous n'avez pas besoin d'ex√©cuter ceci] Code de cr√©ation du jeu de donn√©es.\n",
        "\n",
        "```python\n",
        "# 1. Charger le fichier h5 contenant les jeux de donn√©es CTCF.\n",
        "file_path = os.path.join(ROOT_DIR, 'CTCF_200.h5')\n",
        "\n",
        "with h5py.File(file_path, 'r') as h5file:\n",
        "  print(\"Keys: %s\" % list(h5file.keys()))\n",
        "\n",
        "  # Acc√©der √† chaque jeu de donn√©es et le convertir en tableaux numpy.\n",
        "  x_train = h5file['x_train'][()] # donn√©es d'entra√Ænement\n",
        "  y_train = h5file['y_train'][()] # √©tiquettes d'entra√Ænement\n",
        "  x_valid = h5file['x_valid'][()] # donn√©es de validation\n",
        "  y_valid = h5file['y_valid'][()] # √©tiquettes de validation\n",
        "  x_test = h5file['x_test'][()] # donn√©es de test\n",
        "  y_test = h5file['y_test'][()] # √©tiquettes de test\n",
        "\n",
        "# Chaque s√©quence d'ADN est encod√©e en one-hot. Visualiser le premier exemple d'entra√Ænement¬†:\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "plt.imshow(x_train[0, :, :])\n",
        "plt.show()\n",
        "\n",
        "# 2. √âtant donn√© que notre mod√®le de langage d'ADN prend en r√©alit√© des lettres en entr√©e, nous pouvons annuler\n",
        "# l'encodage one-hot avec une fonction¬†:\n",
        "\n",
        "def one_hot_to_dna_batch(one_hot_encoded_batch: np.ndarray):\n",
        "  \"\"\"\n",
        "  Convertir un lot de s√©quences d'ADN encod√©es en one-hot en cha√Ænes de s√©quences d'ADN.\n",
        "\n",
        "  Args:\n",
        "    one_hot_encoded_batch (numpy.ndarray): Un tableau numpy 3D avec des s√©quences d'ADN\n",
        "      encod√©es en one-hot. La forme doit √™tre (nombre_de_s√©quences, longueur_de_la_s√©quence, 4).\n",
        "\n",
        "  Returns:\n",
        "    list: Une liste de s√©quences d'ADN.\n",
        "  \"\"\"\n",
        "  # D√©finir une correspondance entre l'encodage one-hot et les nucl√©otides.\n",
        "  one_hot_mapping = {\n",
        "      (1, 0, 0, 0): 'A',\n",
        "      (0, 1, 0, 0): 'C',\n",
        "      (0, 0, 1, 0): 'G',\n",
        "      (0, 0, 0, 1): 'T',\n",
        "  }\n",
        "\n",
        "  dna_sequences = []\n",
        "\n",
        "  for one_hot_encoded in one_hot_encoded_batch:\n",
        "    dna_sequence = []\n",
        "    for one_hot in one_hot_encoded:\n",
        "      one_hot_tuple = tuple(one_hot)\n",
        "      dna_sequence.append(one_hot_mapping[one_hot_tuple])\n",
        "\n",
        "    dna_sequences.append(''.join(dna_sequence))\n",
        "\n",
        "  return dna_sequences\n",
        "\n",
        "NUM_TRAIN_EXAMPLES = 20_000\n",
        "NUM_VALID_EXAMPLES = 5_000\n",
        "\n",
        "# exemples d'entra√Ænement (x_train), √©tiquettes d'entra√Ænement (y_train), exemples de validation (x_valid), √©tiquettes de validation (y_valid)\n",
        "x_train = one_hot_to_dna_batch(\n",
        "    np.moveaxis(x_train, 1, -1)[0:NUM_TRAIN_EXAMPLES])\n",
        "y_train = y_train[0:NUM_TRAIN_EXAMPLES]\n",
        "\n",
        "x_valid = one_hot_to_dna_batch(\n",
        "    np.moveaxis(x_valid, 1, -1)[0:NUM_VALID_EXAMPLES])\n",
        "y_valid = y_valid[0:NUM_VALID_EXAMPLES]\n",
        "\n",
        "# Jeter un coup d'≈ìil aux exemples d'entra√Ænement et aux √©tiquettes¬†:\n",
        "print(x_train[0:5])\n",
        "print(y_train[0:5])\n",
        "\n",
        "# 3. Calculer les plongements moyens du mod√®le de langage d'ADN des s√©quences.\n",
        "train_embeddings = compute_mean_sequence_embeddings(\n",
        "    x_train, tokenizer, language_model)\n",
        "train_df = pd.DataFrame(train_embeddings)\n",
        "train_df['label'] = y_train[:, 0]\n",
        "\n",
        "valid_embeddings = compute_mean_sequence_embeddings(\n",
        "    x_valid, tokenizer, language_model)\n",
        "valid_df = pd.DataFrame(valid_embeddings)\n",
        "valid_df['label'] = y_valid[:, 0]\n",
        "```\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJ7HXckUwbfY"
      },
      "source": [
        "## Convertir les donn√©es en un jeu de donn√©es TensorFlow\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4jfUcKiUcTl"
      },
      "source": [
        "Nous devrons convertir ces dataframes en un jeu de donn√©es TensorFlow sur lequel nous pourrons facilement it√©rer lors de l'entra√Ænement du mod√®le¬†:\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-GPb4YWw8ld"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def convert_to_tfds(df: pd.DataFrame, batch_size: int=32,\n",
        "                    is_training: bool=False):\n",
        "    \"\"\"Convertit les plongements et les √©tiquettes en un jeu de donn√©es TensorFlow.\"\"\" # embeddings: plongements, labels: √©tiquettes\n",
        "    embeddings = np.array(df.iloc[:, :-1])\n",
        "    labels = np.array(df.iloc[:, -1])[:, None]\n",
        "\n",
        "    ds = tf.data.Dataset.from_tensor_slices(\n",
        "        {'embeddings': embeddings, 'labels': labels})\n",
        "\n",
        "    if is_training:\n",
        "      ds = ds.shuffle(buffer_size=len(df)).repeat()\n",
        "\n",
        "    ds = ds.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return iter(ds)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_ds = convert_to_tfds(\n",
        "    train_df, batch_size=BATCH_SIZE, is_training=True)\n",
        "valid_ds = convert_to_tfds(\n",
        "    valid_df, batch_size=BATCH_SIZE, is_training=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufGd4gz1oiCi"
      },
      "source": [
        "Jetons un coup d'≈ìil √† un lot de donn√©es d'entra√Ænement¬†:\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6U56UKQWxjdv"
      },
      "outputs": [],
      "source": [
        "batch = next(train_ds)\n",
        "batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2CzBBJxVTAG"
      },
      "source": [
        "Le jeu de donn√©es est pr√™t pour l'entra√Ænement du mod√®le¬†!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80wbx6lTofFI"
      },
      "source": [
        "## R√©glage fin du mod√®le\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vwwXzz1i3Dq"
      },
      "source": [
        "Nous allons maintenant entra√Æner un mod√®le lin√©aire [flax](https://flax.readthedocs.io/en/latest/) simple sur les plongements d'ADN moyens.\n",
        "\n",
        "Flax est assez similaire √† de nombreux autres frameworks de deep learning (en particulier [Haiku](https://dm-haiku.readthedocs.io/en/latest/), si vous l'avez d√©j√† rencontr√©). Dans notre configuration, notez que notre mod√®le n'est qu'un MLP (perceptron multicouche, qui est constitu√© de plusieurs couches lin√©aires avec quelques non-lin√©arit√©s) - nous ne modifions pas (r√©tropropagation dans) le mod√®le linguistique d'ADN original.\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAxz08WTOeTb"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "  dim: int = 128\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    x = nn.Dense(self.dim * 2)(x)\n",
        "    x = nn.gelu(x)\n",
        "    x = nn.Dense(self.dim)(x)\n",
        "    x = nn.gelu(x)\n",
        "    x = nn.Dense(1)(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPrdkSM-c2VT"
      },
      "outputs": [],
      "source": [
        "mlp = Model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kve15vj32elg"
      },
      "source": [
        "### Boucle d'entra√Ænement (Training loop)\n",
        "\n",
        "Avec le mod√®le et les donn√©es mis en place, nous pouvons maintenant initialiser les param√®tres de notre mod√®le, notre optimiseur, et √©crire une fonction pour effectuer une seule √©tape d'entra√Ænement (qui englobe une passe avant du mod√®le (model forward pass), un calcul de la perte (loss computation), un calcul du gradient (gradient computation) et une mise √† jour des param√®tres du mod√®le √† l'aide des gradients) :\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzvdOVyRPaF7"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE = 0.0001\n",
        "\n",
        "init_rng = jax.random.PRNGKey(42)\n",
        "variables = mlp.init(init_rng, batch['embeddings']) # batch: lot\n",
        "params = variables['params']\n",
        "\n",
        "optimiser = optax.adam(LEARNING_RATE)\n",
        "opt_state = optimiser.init(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CQe4CHuvmPx"
      },
      "source": [
        "Vous pouvez v√©rifier les noms des couches dans notre r√©seau de neurones comme ceci :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3EbmNT5vhXX"
      },
      "outputs": [],
      "source": [
        "params.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgOUFfqRvpTw"
      },
      "source": [
        "Et v√©rifiez que la forme de cette couche correspond √† ce que vous attendez comme ceci¬†:\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZaFLwwAvtO8"
      },
      "outputs": [],
      "source": [
        "for layer_name in ['Dense_0', 'Dense_1', 'Dense_2']:\n",
        "      print(params[layer_name]['kernel'].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQVRPJ76v_nA"
      },
      "source": [
        "**Question** : Pouvez-vous d√©terminer d'o√π proviennent ces formes, √©tant donn√© notre code dans notre `class Model` ci-dessus ?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSfHeH5zyqBd"
      },
      "source": [
        "Nous pourrions d√©j√† faire des pr√©dictions en utilisant ces param√®tres initialis√©s al√©atoirement (seulement, les pr√©dictions seront al√©atoires)¬†:\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpzUpbHdyYwY"
      },
      "outputs": [],
      "source": [
        "preds = mlp.apply({'params': params}, batch['embeddings'])\n",
        "nn.sigmoid(preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvRto9Nky_40"
      },
      "source": [
        "D√©finissons maintenant une fonction de perte que nous pouvons utiliser pour entra√Æner ces param√®tres¬†:\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgM5xJW6x8Hm"
      },
      "outputs": [],
      "source": [
        "def loss_fn(params, embeddings, labels):\n",
        "  \"\"\"Applique la fonction sigmo√Øde aux logits et calcule la perte d'entropie crois√©e binaire (binary cross-entropy loss).\"\"\"\n",
        "  logits = mlp.apply({'params': params}, embeddings)\n",
        "  loss = optax.sigmoid_binary_cross_entropy(\n",
        "      logits=logits, labels=labels).mean()\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOkY0h3C0LuR"
      },
      "source": [
        "Calculons un exemple de perte¬†:\n",
        "     \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqkzxWnxyRA2"
      },
      "outputs": [],
      "source": [
        "embeddings = jnp.array(batch['embeddings'])\n",
        "labels = jnp.array(batch['labels']) # (labels: √©tiquettes)\n",
        "loss_fn(params, embeddings, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nro6FSdK_6Ji"
      },
      "source": [
        "Donc, nous nous attendons √† une perte autour de 0.6-0.7 pour des poids initialis√©s al√©atoirement. Avec un peu de chance, avec l'entra√Ænement du mod√®le, nous devrions voir des pertes plus faibles que cela √† mesure que le mod√®le apprend le signal dans les donn√©es¬†! :)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7LRUb1l0N2F"
      },
      "source": [
        "Finalement, nous pouvons √©crire une fonction √©tape d'entra√Ænement¬†:\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJ4PNA1pvZRI"
      },
      "outputs": [],
      "source": [
        "@jax.jit\n",
        "def train_step(params, opt_state, embeddings, labels):\n",
        "  \"\"\"Une seule √©tape d'entra√Ænement qui calcule les gradients et met √† jour les param√®tres du mod√®le.\"\"\"\n",
        "  loss, grads = jax.value_and_grad(loss_fn)(params, embeddings, labels)\n",
        "  updates, opt_state = optimiser.update(grads, opt_state)\n",
        "  params = optax.apply_updates(params, updates)\n",
        "  return params, opt_state, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47VtoXKw403F"
      },
      "source": [
        "### Entra√Ænons le mod√®le¬†!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rljY6Nx_Oar"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 5\n",
        "NUM_TRAINING_STEPS = (len(train_df) // BATCH_SIZE) * NUM_EPOCHS\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# R√©initialise le mod√®le pour s'assurer qu'il d√©marre √† z√©ro √† chaque fois que la cellule est ex√©cut√©e.\n",
        "init_rng = jax.random.PRNGKey(42)\n",
        "variables = mlp.init(init_rng, batch['embeddings'])\n",
        "params = variables['params']\n",
        "\n",
        "optimiser = optax.adam(LEARNING_RATE)\n",
        "opt_state = optimiser.init(params)\n",
        "\n",
        "# Conserve un enregistrement des pertes.\n",
        "running_train_loss = None\n",
        "running_train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in tqdm.tqdm(range(NUM_EPOCHS)):\n",
        "\n",
        "  # Boucle d'entra√Ænement.\n",
        "  for step in range(NUM_TRAINING_STEPS):\n",
        "    batch = next(train_ds)\n",
        "    embeddings = jnp.array(batch['embeddings'])\n",
        "    labels = jnp.array(batch['labels'])\n",
        "    params, opt_state, loss = train_step(params, opt_state, embeddings, labels)\n",
        "\n",
        "    if running_train_loss is None:\n",
        "      running_train_loss = loss.item()\n",
        "    else:\n",
        "      running_train_loss = 0.99 * running_train_loss + (1 - 0.99) * loss.item()\n",
        "    running_train_losses.append(running_train_loss)\n",
        "\n",
        "  # Boucle de validation.\n",
        "  valid_ds = convert_to_tfds(valid_df, batch_size=BATCH_SIZE, is_training=False)\n",
        "  for batch in valid_ds:\n",
        "    embeddings = jnp.array(batch['embeddings'])\n",
        "    labels = jnp.array(batch['labels'])\n",
        "    loss = loss_fn(params, embeddings, labels)\n",
        "    valid_losses.append(loss.item())\n",
        "\n",
        "  valid_loss = np.mean(valid_losses)\n",
        "  print(f'[Epoch {epoch}]: Valid loss (Perte de validation)={valid_loss:.3f}, '\n",
        "        f'Train loss (Perte d\\'entra√Ænement)={running_train_loss:.3f}\\n')\n",
        "\n",
        "print('Entra√Ænement termin√©.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNxoqkSbGvtr"
      },
      "source": [
        "üéâ üéâ **Et voil√†, l'entra√Ænement de base du mod√®le est termin√©¬†!** üéâ üéâ\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qQ4NafPHCsL"
      },
      "source": [
        "## V√©rification du mod√®le\n",
        "\n",
        "Nous pouvons essayer d'inf√©rer le mod√®le entra√Æn√© sur n'importe quelle nouvelle s√©quence d'ADN d'int√©r√™t. Par exemple, comme nous savons gr√¢ce √† des exp√©riences biologiques que la prot√©ine CTCF se lie aux s√©quences d'ADN contenant des motifs similaires √† ¬´¬†CCACCAGGGGGCGC¬†¬ª, le mod√®le devrait pr√©dire une probabilit√© tr√®s √©lev√©e de liaison pour l'ADN contenant ces motifs.\n",
        "\n",
        "Construisons la cha√Æne d'ADN de 200¬†bases et r√©cup√©rons son incorporation¬†:\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knsDFhP5HCx7"
      },
      "outputs": [],
      "source": [
        "ctcf_motif_dna = 'CCACCAGGGGGCGC'*14 + 'AAAA'\n",
        "print('Longueur de la cha√Æne d\\'ADN remplie de motifs CTCF¬†:', len(ctcf_motif_dna))\n",
        "\n",
        "# (ctcf_motif_dna, ctcf_motif_embedding) -> (s√©quence_adn_motif_ctcf, incorporation_motif_ctcf)\n",
        "ctcf_motif_embedding = compute_mean_sequence_embeddings(\n",
        "    [ctcf_motif_dna], tokenizer, language_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM_yTcpcILFm"
      },
      "source": [
        "Nous pouvons maintenant calculer la probabilit√© que l'ADN se lie au CTCF¬†:\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9L7HI9d_HdkY"
      },
      "outputs": [],
      "source": [
        "jax.nn.sigmoid(mlp.apply({'params': params}, ctcf_motif_embedding))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vf3cVUYtIO4D"
      },
      "source": [
        "Succ√®s ! Cette probabilit√© est tr√®s proche de 1. Cela signifie que le mod√®le a appris √† identifier une repr√©sentation de ce motif et √† l'associer √† la liaison de CTCF √† l'ADN.\n",
        "\n",
        "Inversement, les cha√Ænes d'ADN al√©atoires devraient avoir une faible probabilit√© de liaison avec CTCF¬†:\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgadMGYYGs5E"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "random_dna_strings = [\n",
        "    'ACGTACGT'*25,\n",
        "    'CGGCCGCG'*25,\n",
        "    'TCGATCGT'*25,\n",
        "    'TTTTTTTT'*25,\n",
        "]\n",
        "\n",
        "probabilities = []\n",
        "\n",
        "# (random_dna_string:cha√Æne d'ADN al√©atoire)\n",
        "for random_dna_string in random_dna_strings:\n",
        "  # (random_dna_embedding:plongement d'ADN al√©atoire)\n",
        "  random_dna_embedding = compute_mean_sequence_embeddings(\n",
        "    [random_dna_string], tokenizer, language_model)\n",
        "\n",
        "  probabilities.append(\n",
        "      jax.nn.sigmoid(mlp.apply({'params': params}, random_dna_embedding))[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6nL2PwKWhZG"
      },
      "outputs": [],
      "source": [
        "probabilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5euD1_nI2RL"
      },
      "source": [
        "G√©nial, celles-ci ressemblent toutes √† des probabilit√©s proches de z√©ro, ce √† quoi nous nous attendions üòé.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17otXl0aGzyx"
      },
      "source": [
        "## [Suivis Facultatifs]\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHSPk0yVG5w8"
      },
      "source": [
        "\n",
        "1. **[Trac√© des pertes]** Essayez de tracer la perte d'entra√Ænement et la perte de validation au fil du temps. Qu'observez-vous ? Devrions-nous l'entra√Æner plus longtemps ? Y a-t-il un surajustement √† l'ensemble d'entra√Ænement ? Si oui, comment pourriez-vous am√©liorer la situation ?\n",
        " - **Indice** : essayez `plt.plot(train_losses, c='grey')`.\n",
        "2. **[M√©triques d'√©valuation]** Jusqu'√† pr√©sent, nous n'avons surveill√© que les pertes pendant l'entra√Ænement du mod√®le, mais celles-ci sont un peu difficiles √† interpr√©ter. Comment pourriez-vous impl√©menter et suivre une mesure de **pr√©cision** pendant l'entra√Ænement ?\n",
        " - **Indice** : N'oubliez pas que si vous utilisez `jax.nn.sigmoid` sur les pr√©dictions du mod√®le, cela donne la probabilit√© que la s√©quence d'ADN se lie √† la prot√©ine CTCF. Vous pouvez traiter toute probabilit√© sup√©rieure √† 0,5 comme une pr√©diction de '1', et toute probabilit√© inf√©rieure √† 0,5 comme une pr√©diction de '0'.\n",
        "3. **[R√©glage des hyperparam√®tres]** Essayez de faire varier le taux d'apprentissage, la taille du lot (batch size) et le nombre d'√©tapes d'entra√Ænement. Comment ces changements affectent-ils la convergence et la performance finale du mod√®le ?\n",
        "4. **[Augmentation des donn√©es]** Pouvez-vous penser √† un moyen d'√©largir (ou d'augmenter) l'ensemble d'entra√Ænement ? Comment mesureriez-vous si cela est utile pour la performance du mod√®le ?\n",
        "5. **[Architectures diff√©rentes]** Exp√©rimentez avec diff√©rentes architectures de mod√®le, comme l'ajout de couches suppl√©mentaires ou l'utilisation de diff√©rentes fonctions d'activation.\n",
        " - **D√©fi** : si vous vous sentez tr√®s aventureux, essayez d'impl√©menter un CNN capable d'apprendre directement √† partir de s√©quences d'ADN (cod√©es en one-hot) !\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Commentaires\n",
        "\n",
        "N'h√©sitez pas √† nous faire part de vos commentaires afin que nous puissions am√©liorer nos ateliers pratiques √† l'avenir.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title G√©n√©rer un formulaire de commentaires (Ex√©cuter la cellule)\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\n",
        "    \"\"\"\n",
        "<iframe\n",
        "\tsrc=\"https://forms.gle/WUpRupqfhFtbLXtN6\",\n",
        "  width=\"80%\"\n",
        "\theight=\"1200px\" >\n",
        "\tLoading...\n",
        "</iframe>\n",
        "\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://baobab.deeplearningindaba.com/static/media/indaba-logo-dark.d5a6196d.png\" width=\"50%\" />"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
